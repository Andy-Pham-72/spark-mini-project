[root@sandbox-hdp ~]# spark-submit AutoSaleExtractSpark.py                                                                     
SPARK_MAJOR_VERSION is set to 2, using Spark2
22/02/18 15:22:06 INFO SparkContext: Running Spark version 2.3.1.3.0.1.0-187
22/02/18 15:22:06 INFO SparkContext: Submitted application: My Application
22/02/18 15:22:06 INFO SecurityManager: Changing view acls to: root
22/02/18 15:22:06 INFO SecurityManager: Changing modify acls to: root
22/02/18 15:22:06 INFO SecurityManager: Changing view acls groups to: 
22/02/18 15:22:06 INFO SecurityManager: Changing modify acls groups to: 
22/02/18 15:22:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permission
s: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: S
et()
22/02/18 15:22:07 INFO Utils: Successfully started service 'sparkDriver' on port 43295.
22/02/18 15:22:07 INFO SparkEnv: Registering MapOutputTracker
22/02/18 15:22:07 INFO SparkEnv: Registering BlockManagerMaster
22/02/18 15:22:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology in
formation
22/02/18 15:22:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/02/18 15:22:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ee0c0111-c6f1-4154-9bc3-d3ed76c33ee9
22/02/18 15:22:07 INFO MemoryStore: MemoryStore started with capacity 93.3 MB
22/02/18 15:22:07 INFO SparkEnv: Registering OutputCommitCoordinator
22/02/18 15:22:07 INFO log: Logging initialized @2586ms
22/02/18 15:22:07 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d
1bba2cc8ab69827
22/02/18 15:22:07 INFO Server: Started @2695ms
22/02/18 15:22:07 INFO AbstractConnector: Started ServerConnector@616a3d0b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
22/02/18 15:22:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@40b5e8c5{/jobs,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@22077093{/jobs/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@67a2a391{/jobs/job,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2c727cd1{/jobs/job/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@35680224{/stages,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@47249133{/stages/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@51692738{/stages/stage,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7880bcad{/stages/stage/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@60c81462{/stages/pool,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1c1f6e86{/stages/pool/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77650780{/storage,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@afda815{/storage/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2a36c62c{/storage/rdd,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4d3ae6b2{/storage/rdd/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@12bca192{/environment,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75e61ed0{/environment/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@69fda1e6{/executors,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@73e8c51d{/executors/json,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4af5ac3{/executors/threadDump,null,AVAILABLE,@Spar
k}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@417ad418{/executors/threadDump/json,null,AVAILABLE
,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@458caf40{/static,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@39ba22f6{/,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@217f1030{/api,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@181c1f66{/jobs/job/kill,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@46140fd8{/stages/stage/kill,null,AVAILABLE,@Spark}
22/02/18 15:22:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sandbox-hdp.hortonworks.com:4040
22/02/18 15:22:07 INFO Executor: Starting executor ID driver on host localhost                                                 
22/02/18 15:22:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4
2849.                                                                                                                          
22/02/18 15:22:07 INFO NettyBlockTransferService: Server created on sandbox-hdp.hortonworks.com:42849                          
22/02/18 15:22:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy  
22/02/18 15:22:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42849, 
None)                                                                                                                          
22/02/18 15:22:07 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:42849 with 93.3 MB RAM
, BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42849, None)                                                             
22/02/18 15:22:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42849, N
one)                                                                                                                           
22/02/18 15:22:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42849, None)
22/02/18 15:22:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@29d4b1fd{/metrics/json,null,AVAILABLE,@Spark}     
22/02/18 15:22:09 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/local-1645197727831                        
22/02/18 15:22:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 363.4 KB, free 92.9 MB)       
22/02/18 15:22:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.4 KB, free 92.9 MB)  
22/02/18 15:22:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:42849 (size: 30.4 KB
, free: 93.3 MB)                                                                                                               
22/02/18 15:22:10 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0                      
22/02/18 15:22:10 INFO FileInputFormat: Total input files to process : 1                                                       
22/02/18 15:22:11 INFO SparkContext: Starting job: collect at /root/AutoSaleExtractSpark.py:21                                 
22/02/18 15:22:11 INFO DAGScheduler: Registering RDD 3 (groupByKey at /root/AutoSaleExtractSpark.py:15)                        
22/02/18 15:22:11 INFO DAGScheduler: Registering RDD 7 (reduceByKey at /root/AutoSaleExtractSpark.py:21)                       
22/02/18 15:22:11 INFO DAGScheduler: Got job 0 (collect at /root/AutoSaleExtractSpark.py:21) with 1 output partitions          
22/02/18 15:22:11 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /root/AutoSaleExtractSpark.py:21)                  
22/02/18 15:22:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)                                           
22/02/18 15:22:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)                                                  
22/02/18 15:22:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/AutoSaleExtractSpark.p
y:15), which has no missing parents                                                                                            
22/02/18 15:22:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.9 KB, free 92.9 MB)         
22/02/18 15:22:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 92.9 MB)   
22/02/18 15:22:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:42849 (size: 6.2 KB,
 free: 93.3 MB)                                                                                                                
22/02/18 15:22:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039                             
22/02/18 15:22:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/A
utoSaleExtractSpark.py:15) (first 15 tasks are for partitions Vector(0))                                                       
22/02/18 15:22:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks                                                     
22/02/18 15:22:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 790
3 bytes)                                                                                                                       
22/02/18 15:22:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)                                                         
22/02/18 15:22:11 INFO HadoopRDD: Input split: hdfs://sandbox-hdp.hortonworks.com:8020/user/root/test_dir/data.csv:0+993       
22/02/18 15:22:12 INFO PythonRunner: Times: total = 375, boot = 242, init = 124, finish = 9                                    
22/02/18 15:22:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1733 bytes result sent to driver                      
22/02/18 15:22:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 963 ms on localhost (executor driver) (1/1)   
22/02/18 15:22:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool                       
22/02/18 15:22:12 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 59003                      
22/02/18 15:22:12 INFO DAGScheduler: ShuffleMapStage 0 (groupByKey at /root/AutoSaleExtractSpark.py:15) finished in 1.103 s    
22/02/18 15:22:12 INFO DAGScheduler: looking for newly runnable stages                                                         
22/02/18 15:22:12 INFO DAGScheduler: running: Set()                                                                            
22/02/18 15:22:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)                                            
22/02/18 15:22:12 INFO DAGScheduler: failed: Set()                                                                             
22/02/18 15:22:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/AutoSaleExtractSpark.
py:21), which has no missing parents                                                                                           
22/02/18 15:22:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.5 KB, free 92.9 MB)        
22/02/18 15:22:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 92.9 MB)   
22/02/18 15:22:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:42849 (size: 6.5 KB,
 free: 93.3 MB)                                                                                                                
22/02/18 15:22:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039                             
22/02/18 15:22:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/
AutoSaleExtractSpark.py:21) (first 15 tasks are for partitions Vector(0))                                                      
22/02/18 15:22:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks                                                     
22/02/18 15:22:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 763
8 bytes)                                                                                                                       
22/02/18 15:22:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)                                                         
22/02/18 15:22:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks                                 
22/02/18 15:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms                                          
22/02/18 15:22:12 INFO PythonRunner: Times: total = 45, boot = -533, init = 577, finish = 1                                    
[root@sandbox-hdp ~]# spark-submit AutoSaleExtractSpark.py                                                                     
SPARK_MAJOR_VERSION is set to 2, using Spark2
22/02/18 15:23:06 INFO SparkContext: Running Spark version 2.3.1.3.0.1.0-187
22/02/18 15:23:06 INFO SparkContext: Submitted application: My Application
22/02/18 15:23:06 INFO SecurityManager: Changing view acls to: root
22/02/18 15:23:06 INFO SecurityManager: Changing modify acls to: root
22/02/18 15:23:06 INFO SecurityManager: Changing view acls groups to: 
22/02/18 15:23:06 INFO SecurityManager: Changing modify acls groups to: 
22/02/18 15:23:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permission
s: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: S
et()
22/02/18 15:23:06 INFO Utils: Successfully started service 'sparkDriver' on port 35801.
22/02/18 15:23:06 INFO SparkEnv: Registering MapOutputTracker
22/02/18 15:23:07 INFO SparkEnv: Registering BlockManagerMaster
22/02/18 15:23:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology in
formation
22/02/18 15:23:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/02/18 15:23:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5dde4599-9fbb-4a54-924e-6075b023fa31
22/02/18 15:23:07 INFO MemoryStore: MemoryStore started with capacity 93.3 MB
22/02/18 15:23:07 INFO SparkEnv: Registering OutputCommitCoordinator
22/02/18 15:23:07 INFO log: Logging initialized @2056ms
22/02/18 15:23:07 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d
1bba2cc8ab69827
22/02/18 15:23:07 INFO Server: Started @2156ms
22/02/18 15:23:07 INFO AbstractConnector: Started ServerConnector@5a617b42{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
22/02/18 15:23:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@449b27e8{/jobs,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1f702ae0{/jobs/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6544fc20{/jobs/job,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@441c575d{/jobs/job/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5a254214{/stages,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1842008c{/stages/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@25143a9d{/stages/stage,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7b1fc8df{/stages/stage/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7f5bc5f3{/stages/pool,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5d53af0a{/stages/pool/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@21fc5fc1{/storage,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@24a02211{/storage/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5751f2b{/storage/rdd,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@451ecb70{/storage/rdd/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65f9645{/environment,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@234a8c35{/environment/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@e6b5330{/executors,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3d9d5cc6{/executors/json,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@478a188e{/executors/threadDump,null,AVAILABLE,@Spa
rk}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@30561f6e{/executors/threadDump/json,null,AVAILABLE
,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@64f02887{/static,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@45bafde6{/,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1275bd62{/api,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@9621bd8{/jobs/job/kill,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3603feeb{/stages/stage/kill,null,AVAILABLE,@Spark}
22/02/18 15:23:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sandbox-hdp.hortonworks.com:4040
22/02/18 15:23:07 INFO Executor: Starting executor ID driver on host localhost                                                 
22/02/18 15:23:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4
4497.                                                                                                                          
22/02/18 15:23:07 INFO NettyBlockTransferService: Server created on sandbox-hdp.hortonworks.com:44497                          
22/02/18 15:23:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy  
22/02/18 15:23:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 44497, 
None)                                                                                                                          
22/02/18 15:23:07 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:44497 with 93.3 MB RAM
, BlockManagerId(driver, sandbox-hdp.hortonworks.com, 44497, None)                                                             
22/02/18 15:23:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 44497, N
one)                                                                                                                           
22/02/18 15:23:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sandbox-hdp.hortonworks.com, 44497, None)
22/02/18 15:23:07 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1b80073c{/metrics/json,null,AVAILABLE,@Spark}     
22/02/18 15:23:08 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/local-1645197787447                        
22/02/18 15:23:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 363.4 KB, free 92.9 MB)       
22/02/18 15:23:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.4 KB, free 92.9 MB)  
22/02/18 15:23:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:44497 (size: 30.4 KB
, free: 93.3 MB)                                                                                                               
22/02/18 15:23:09 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0                      
22/02/18 15:23:09 INFO FileInputFormat: Total input files to process : 1                                                       
22/02/18 15:23:09 INFO SparkContext: Starting job: collect at /root/AutoSaleExtractSpark.py:21                                 
22/02/18 15:23:09 INFO DAGScheduler: Registering RDD 3 (groupByKey at /root/AutoSaleExtractSpark.py:15)                        
22/02/18 15:23:09 INFO DAGScheduler: Registering RDD 7 (reduceByKey at /root/AutoSaleExtractSpark.py:21)                       
22/02/18 15:23:09 INFO DAGScheduler: Got job 0 (collect at /root/AutoSaleExtractSpark.py:21) with 1 output partitions          
22/02/18 15:23:09 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /root/AutoSaleExtractSpark.py:21)                  
22/02/18 15:23:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)                                           
22/02/18 15:23:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)                                                  
22/02/18 15:23:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/AutoSaleExtractSpark.p
y:15), which has no missing parents                                                                                            
22/02/18 15:23:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.9 KB, free 92.9 MB)         
22/02/18 15:23:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 92.9 MB)   
22/02/18 15:23:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:44497 (size: 6.2 KB,
 free: 93.3 MB)                                                                                                                
22/02/18 15:23:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039                             
22/02/18 15:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/A
utoSaleExtractSpark.py:15) (first 15 tasks are for partitions Vector(0))                                                       
22/02/18 15:23:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks                                                     
22/02/18 15:23:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 790
3 bytes)                                                                                                                       
22/02/18 15:23:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)                                                         
22/02/18 15:23:10 INFO HadoopRDD: Input split: hdfs://sandbox-hdp.hortonworks.com:8020/user/root/test_dir/data.csv:0+993       
22/02/18 15:23:10 INFO PythonRunner: Times: total = 386, boot = 298, init = 79, finish = 9                                     
22/02/18 15:23:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1733 bytes result sent to driver                      
22/02/18 15:23:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 818 ms on localhost (executor driver) (1/1)   
22/02/18 15:23:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool                       
22/02/18 15:23:10 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 40967                      
22/02/18 15:23:10 INFO DAGScheduler: ShuffleMapStage 0 (groupByKey at /root/AutoSaleExtractSpark.py:15) finished in 0.965 s    
22/02/18 15:23:10 INFO DAGScheduler: looking for newly runnable stages                                                         
22/02/18 15:23:10 INFO DAGScheduler: running: Set()                                                                            
22/02/18 15:23:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)                                            
22/02/18 15:23:10 INFO DAGScheduler: failed: Set()                                                                             
22/02/18 15:23:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/AutoSaleExtractSpark.
py:21), which has no missing parents                                                                                           
22/02/18 15:23:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.5 KB, free 92.9 MB)        
22/02/18 15:23:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 92.9 MB)   
22/02/18 15:23:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:44497 (size: 6.5 KB,
 free: 93.3 MB)                                                                                                                
22/02/18 15:23:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039                             
22/02/18 15:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/
AutoSaleExtractSpark.py:21) (first 15 tasks are for partitions Vector(0))                                                      
22/02/18 15:23:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks                                                     
22/02/18 15:23:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 763
8 bytes)                                                                                                                       
22/02/18 15:23:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)                                                         
22/02/18 15:23:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks                                 
22/02/18 15:23:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms                                          
22/02/18 15:23:11 INFO PythonRunner: Times: total = 44, boot = -480, init = 524, finish = 0                                    
22/02/18 15:23:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1905 bytes result sent to driver                      
22/02/18 15:23:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 195 ms on localhost (executor driver) (1/1)   
22/02/18 15:23:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool                       
22/02/18 15:23:11 INFO DAGScheduler: ShuffleMapStage 1 (reduceByKey at /root/AutoSaleExtractSpark.py:21) finished in 0.207 s   
22/02/18 15:23:11 INFO DAGScheduler: looking for newly runnable stages                                                         
22/02/18 15:23:11 INFO DAGScheduler: running: Set()                                                                            
22/02/18 15:23:11 INFO DAGScheduler: waiting: Set(ResultStage 2)                                                               
22/02/18 15:23:11 INFO DAGScheduler: failed: Set()                                                                             
22/02/18 15:23:11 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[10] at collect at /root/AutoSaleExtractSpark.py:21), w
hich has no missing parents                                                                                                    
22/02/18 15:23:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.6 KB, free 92.9 MB)         
22/02/18 15:23:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.1 KB, free 92.9 MB)   
22/02/18 15:23:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox-hdp.hortonworks.com:44497 (size: 4.1 KB,
 free: 93.3 MB)                                                                                                                
22/02/18 15:23:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039                             
22/02/18 15:23:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[10] at collect at /root/AutoSaleE
xtractSpark.py:21) (first 15 tasks are for partitions Vector(0))                                                               
22/02/18 15:23:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks                                                     
22/02/18 15:23:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 764
9 bytes)                                                                                                                       
22/02/18 15:23:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)                                                         
22/02/18 15:23:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks                                 
22/02/18 15:23:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms                                           
22/02/18 15:23:11 INFO PythonRunner: Times: total = 41, boot = -54, init = 95, finish = 0                                      
22/02/18 15:23:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1840 bytes result sent to driver                      
22/02/18 15:23:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 67 ms on localhost (executor driver) (1/1)    
22/02/18 15:23:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool                       
22/02/18 15:23:11 INFO DAGScheduler: ResultStage 2 (collect at /root/AutoSaleExtractSpark.py:21) finished in 0.080 s           
22/02/18 15:23:11 INFO DAGScheduler: Job 0 finished: collect at /root/AutoSaleExtractSpark.py:21, took 1.398275 s              
[(u'Toyota-2017', 0), (u'Nissan-2003', 1), (u'Mercedes-2015', 2), (u'Mercedes-2016', 1)]                                       
(u'Toyota-2017', 0)                                                                                                            
(u'Nissan-2003', 1)                                                                                                            
(u'Mercedes-2015', 2)                                                                                                          
(u'Mercedes-2016', 1)                                                                                                          
22/02/18 15:23:11 INFO AbstractConnector: Stopped Spark@5a617b42{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}                            
22/02/18 15:23:11 INFO SparkUI: Stopped Spark web UI at http://sandbox-hdp.hortonworks.com:4040                                
22/02/18 15:23:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!                                 
22/02/18 15:23:11 INFO MemoryStore: MemoryStore cleared                                                                        
22/02/18 15:23:11 INFO BlockManager: BlockManager stopped                                                                      
22/02/18 15:23:11 INFO BlockManagerMaster: BlockManagerMaster stopped                                                          
22/02/18 15:23:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!               
22/02/18 15:23:11 INFO SparkContext: Successfully stopped SparkContext                                                         
22/02/18 15:23:12 INFO ShutdownHookManager: Shutdown hook called                                                               
22/02/18 15:23:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-df7be74e-f502-4997-9b8d-1772b2aa5152/pyspark-002474d3
-b8c4-46c0-a4f3-e81455c73630                                                                                                   
22/02/18 15:23:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-994052c2-c106-444d-bce4-d1593eeff8f7                 
22/02/18 15:23:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-df7be74e-f502-4997-9b8d-1772b2aa5152                 
[root@sandbox-hdp ~]# ls                                                                                                       
anaconda-ks.cfg          auto.sh        CarSaleETL.pyc  final_output.txt  mapper2.py    Python-3.4.5.tgz  reducer2.py
AutoSaleExtractSpark.py  CarSaleETL.py  data.csv        mapper1.py        Python-3.4.5  reducer1.py       sparkmini
[root@sandbox-hdp ~]# cat final_output.txt                                                                                     
(u'Toyota-2017', 0)                                                                                                            
(u'Nissan-2003', 1)                                                                                                            
(u'Mercedes-2015', 2)                                                                                                          
(u'Mercedes-2016', 1)      